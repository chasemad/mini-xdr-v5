# ============================================================================
# Mini-XDR EKS Cluster Configuration - Production (CPU-Only, Within Quota)
# ============================================================================
# Optimized for AWS account with 8 vCPU standard instance quota
# - t3.medium nodes: 2 vCPUs, 4GB RAM each
# - 2 nodes minimum, 4 maximum (4-8 vCPUs total, within quota)
# - No GPU requirements - CPU-only ML inference
# - Cost-optimized with autoscaling
# ============================================================================

apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: mini-xdr-cluster
  region: us-east-1
  version: "1.31"
  tags:
    Environment: production
    Project: mini-xdr
    ManagedBy: eksctl
    CostCenter: security-operations

# ============================================================================
# VPC Configuration - Use existing or create new
# ============================================================================
vpc:
  # Option 1: Use existing VPC (recommended if already created)
  # id: "vpc-0d474acd38d418e98"
  # subnets:
  #   private:
  #     us-east-1a: { id: "subnet-0a0622bf540f3849c" }
  #     us-east-1b: { id: "subnet-0d116b9d4a8ac6b49" }
  #   public:
  #     us-east-1a: { id: "subnet-08e1fac778ab053a7" }
  #     us-east-1b: { id: "subnet-0f70f92833d4a5b54" }

  # Option 2: Create new VPC (if not exists)
  cidr: 10.0.0.0/16
  nat:
    gateway: Single  # Cost optimization: Single NAT gateway
  clusterEndpoints:
    publicAccess: true  # Allow kubectl access from anywhere (secured by IAM)
    privateAccess: true

# ============================================================================
# IAM Configuration
# ============================================================================
iam:
  withOIDC: true  # Required for IAM roles for service accounts
  serviceAccounts:
    # AWS Load Balancer Controller service account
    - metadata:
        name: aws-load-balancer-controller
        namespace: kube-system
      wellKnownPolicies:
        awsLoadBalancerController: true

    # Mini-XDR backend service account (with AWS permissions)
    - metadata:
        name: mini-xdr-backend
        namespace: mini-xdr
      attachPolicyARNs:
        - "arn:aws:iam::aws:policy/SecretsManagerReadWrite"  # For secrets
        - "arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy"  # For metrics
      roleName: mini-xdr-backend-role

    # EBS CSI Driver service account
    - metadata:
        name: ebs-csi-controller-sa
        namespace: kube-system
      wellKnownPolicies:
        ebsCSIController: true

    # EFS CSI Driver service account
    - metadata:
        name: efs-csi-controller-sa
        namespace: kube-system
      wellKnownPolicies:
        efsCSIController: true

# ============================================================================
# Managed Node Groups - CPU-Only (Within 8 vCPU Quota)
# ============================================================================
managedNodeGroups:
  # Primary node group - t3.medium (2 vCPUs, 4GB RAM)
  - name: mini-xdr-ng-primary
    instanceType: t3.medium

    # Capacity configuration (within quota)
    desiredCapacity: 2  # Start with 2 nodes (4 vCPUs)
    minSize: 2          # Minimum 2 for HA
    maxSize: 4          # Maximum 4 nodes (8 vCPUs, at quota limit)

    # Volume configuration
    volumeSize: 30      # 30GB per node (sufficient for system + container images)
    volumeType: gp3     # gp3 for better IOPS at same price as gp2
    volumeEncrypted: true

    # Networking
    privateNetworking: true  # Nodes in private subnets

    # SSH access (for debugging only - remove in production)
    ssh:
      allow: false  # Disable SSH for security
      # publicKeyName: mini-xdr-eks-key  # Enable only if needed

    # Labels for workload scheduling
    labels:
      role: application
      environment: production
      workload-type: cpu-ml
      instance-type: t3-medium

    # Tags for AWS resource tracking
    tags:
      k8s.io/cluster-autoscaler/mini-xdr-cluster: "owned"
      k8s.io/cluster-autoscaler/enabled: "true"
      Project: mini-xdr
      Environment: production
      NodeGroup: primary

    # IAM policies for nodes
    iam:
      withAddonPolicies:
        autoScaler: true          # For cluster autoscaler
        albIngress: true          # For ALB ingress controller
        cloudWatch: true          # For CloudWatch logs/metrics
        ebs: true                 # For EBS CSI driver
        efs: true                 # For EFS CSI driver
        externalDNS: true         # For external DNS management

    # Update strategy
    updateConfig:
      maxUnavailable: 1  # Update one node at a time

    # Spot instances (optional cost savings - 70% cheaper)
    # Uncomment if acceptable to have occasional node replacements
    # spot: true
    # spotAllocationStrategy: capacity-optimized
    # instancesDistribution:
    #   spotMaxPrice: 0.0416  # Max price for t3.medium (on-demand price)

# ============================================================================
# Addons - Essential Kubernetes add-ons
# ============================================================================
addons:
  - name: vpc-cni
    version: latest
    attachPolicyARNs:
      - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy

  - name: coredns
    version: latest

  - name: kube-proxy
    version: latest

  - name: aws-ebs-csi-driver
    version: latest
    attachPolicyARNs:
      - arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy

  # AWS EFS CSI Driver (for shared model storage)
  - name: aws-efs-csi-driver
    version: latest
    attachPolicyARNs:
      - arn:aws:iam::aws:policy/service-role/AmazonEFSCSIDriverPolicy

# ============================================================================
# CloudWatch Logging
# ============================================================================
cloudWatch:
  clusterLogging:
    enableTypes:
      - "api"             # API server logs
      - "audit"           # Audit logs for security
      - "authenticator"   # Authentication logs
      - "controllerManager"
      - "scheduler"
    logRetentionInDays: 7  # 7 days retention to save costs

# ============================================================================
# Cluster Access Management
# ============================================================================
# Allow IAM users/roles to access the cluster
# iam:
#   withOIDC: true
#   serviceAccounts: [defined above]
#   iamIdentityMappings:
#     - arn: "arn:aws:iam::ACCOUNT_ID:user/YOUR_IAM_USER"
#       username: admin
#       groups:
#         - system:masters

# ============================================================================
# Cluster Configuration
# ============================================================================
# Enable secrets encryption using AWS KMS
secretsEncryption:
  keyARN: ${KMS_KEY_ARN}  # Will be created by infrastructure script

# ============================================================================
# Cost Estimation (us-east-1, monthly):
# - EKS control plane: $73/month (flat fee)
# - 2x t3.medium nodes: ~$60/month (on-demand)
# - 60GB EBS gp3: ~$5/month
# - NAT gateway: ~$32/month
# - Data transfer: ~$10/month
# - Total: ~$180/month
#
# With Spot instances: ~$120/month (40% savings)
#
# Scaling:
# - At min (2 nodes): 4 vCPUs, 8GB RAM
# - At max (4 nodes): 8 vCPUs, 16GB RAM (at quota limit)
#
# Workload capacity (at max scale):
# - Backend: 4 pods x 1 vCPU = 4 vCPUs
# - Frontend: 4 pods x 0.25 vCPU = 1 vCPU
# - System: ~1 vCPU
# - Total: ~6 vCPUs utilized (2 vCPU headroom)
# ============================================================================
